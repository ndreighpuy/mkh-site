"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[32],{1556:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var s=n(6075),i=n(4848),r=n(8453);const a={slug:"web-scraping-using-python",title:"Web Scraping using Python",authors:"khadaffy",tags:["webscrape","scraping","python","beautifulsoup"]},o="Why Python for Web Scraping?",l={authorsImageUrls:[void 0]},c=[{value:"A Pretty Simple Example",id:"a-pretty-simple-example",level:3},{value:"Ethical Considerations - Scraping Responsibly",id:"ethical-considerations---scraping-responsibly",level:2},{value:"What Else Can I Do?",id:"what-else-can-i-do",level:2}];function h(e){const t={blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:"https://miro.medium.com/v2/resize:fit:720/format:webp/1*atk74YuoKuEn_b-Qs8nOgg.png",alt:"Webscraping - BeautifulSoup"})}),"\n",(0,i.jsx)("center",{children:(0,i.jsx)("em",{children:"Image by: Mohammad Reza"})}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(t.p,{children:"Python stands out as an excellent choice for web scraping due to its inherent simplicity and readability, making it accessible for both beginners and experienced coders. Its true power in this domain, however, lies in its rich ecosystem of specialized libraries. Notably, Beautiful Soup excels at parsing the intricate structure of HTML and XML documents, acting as your guide to easily navigate and pinpoint desired elements within a webpage. Complementing this, the Requests library provides the essential functionality to send HTTP requests, effectively fetching the content of web pages for your scraping endeavors. Furthermore, the vast and active Python community ensures ample resources, tutorials, and support are readily available should you encounter any challenges along your scraping journey."}),"\n",(0,i.jsx)(t.h3,{id:"a-pretty-simple-example",children:"A Pretty Simple Example"}),"\n",(0,i.jsxs)(t.p,{children:["Using ",(0,i.jsx)(t.code,{children:"BeautifulSoup"})," -"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'import requests\r\nfrom bs4 import BeautifulSoup\r\n\r\n# The URL of the webpage we want to scrape\r\nurl = "https://www.example.com"\r\n\r\n# Send an HTTP GET request to the URL\r\nresponse = requests.get(url)\r\nresponse.raise_for_status() # Raise an exception for bad status codes\r\n\r\n# Parse the HTML content using Beautiful Soup\r\nsoup = BeautifulSoup(response.content, \'html.parser\')\r\n\r\n# Find the title tag\r\ntitle_tag = soup.find(\'title\')\r\n\r\n# Extract the text from the title tag\r\nif title_tag:\r\n    title = title_tag.text\r\n    print(f"The title of the page is: {title}")\r\nelse:\r\n    print("Could not find the title tag.")\n'})}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"In this code"}),":"]}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:["We import the ",(0,i.jsx)(t.code,{children:"requests"})," and ",(0,i.jsx)(t.code,{children:"BeautifulSoup"})," libraries."]}),"\n",(0,i.jsxs)(t.li,{children:["We define the ",(0,i.jsx)(t.code,{children:"url"})," of the webpage we want to scrape."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"requests.get(url)"})," sends a request to the specified URL and retrieves the HTML content."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"response.raise_for_status()"})," is good practice to check if the request was successful (no error codes)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"BeautifulSoup(response.content, 'html.parser')"})," creates a BeautifulSoup object, parsing the HTML content. ",(0,i.jsx)(t.code,{children:"'html.parser'"})," is the parser we're using."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"soup.find('title')"})," searches the parsed HTML for the first ",(0,i.jsx)(t.code,{children:"<title>"})," tag."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"title_tag.text"})," extracts the text content within the ",(0,i.jsx)(t.code,{children:"<title>"})," tag."]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"ethical-considerations---scraping-responsibly",children:"Ethical Considerations - Scraping Responsibly"}),"\n",(0,i.jsx)(t.p,{children:"It's crucial to talk about ethics when it comes to web scraping. Remember that websites are someone else's property, and we need to be respectful. Here are a few key points to keep in mind:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Most websites have a robots.txt file that specifies which parts of the site should not be accessed by bots (including your scraper). Always respect these rules. You can usually find it at yourwebsite.com/robots.txt."}),"\n",(0,i.jsx)(t.li,{children:"Make your requests at a reasonable rate to avoid overwhelming the website's server. Implement delays between requests."}),"\n",(0,i.jsx)(t.li,{children:"Some websites explicitly prohibit scraping in their terms of service. Make sure you're not violating these terms."}),"\n",(0,i.jsx)(t.li,{children:"Avoid extracting excessive data that you won't actually use."}),"\n",(0,i.jsx)(t.li,{children:"Be mindful of how you use the scraped data and avoid infringing on copyrights or privacy."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"what-else-can-i-do",children:"What Else Can I Do?"}),"\n",(0,i.jsx)(t.p,{children:"As I become more comfortable with the basics, I can explore more advanced techniques such as:"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"Scraping data from websites with pagination."}),"\n",(0,i.jsx)(t.li,{children:"Handling websites that use JavaScript to load content (you might need tools like Selenium for this)."}),"\n",(0,i.jsx)(t.li,{children:"More precise ways to target specific elements in the HTML."}),"\n",(0,i.jsx)(t.li,{children:"Saving your extracted data into various formats like CSV, JSON, or databases."}),"\n"]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsxs)(t.p,{children:["So, are you ready to dive in? Start with the basics, explore the power of ",(0,i.jsx)(t.code,{children:"requests"})," and ",(0,i.jsx)(t.code,{children:"BeautifulSoup"}),", Happy scraping and always remember to scrape responsibly."]}),"\n"]})]})}function p(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},6075:e=>{e.exports=JSON.parse('{"permalink":"/web-scraping-using-python","source":"@site/blog/2018-11-24-web-scraping-using-python.md","title":"Web Scraping using Python","description":"Webscraping - BeautifulSoup","date":"2018-11-24T00:00:00.000Z","tags":[{"inline":true,"label":"webscrape","permalink":"/tags/webscrape"},{"inline":true,"label":"scraping","permalink":"/tags/scraping"},{"inline":true,"label":"python","permalink":"/tags/python"},{"inline":true,"label":"beautifulsoup","permalink":"/tags/beautifulsoup"}],"readingTime":2.75,"hasTruncateMarker":true,"authors":[{"name":"Muhamad Khadaffy","title":"Full Stack Dev","url":"https://github.com/reighpuy","page":{"permalink":"/authors/khadaffy"},"socials":{"instagram":"https://www.instagram.com/reighpuy","github":"https://github.com/reighpuy"},"imageURL":"https://github.com/reighpuy.png","key":"khadaffy"}],"frontMatter":{"slug":"web-scraping-using-python","title":"Web Scraping using Python","authors":"khadaffy","tags":["webscrape","scraping","python","beautifulsoup"]},"unlisted":false,"prevItem":{"title":"Intro","permalink":"/intro"},"nextItem":{"title":"Base64 Encoder in Python","permalink":"/base64-encoder-in-python"}}')},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>o});var s=n(6540);const i={},r=s.createContext(i);function a(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);